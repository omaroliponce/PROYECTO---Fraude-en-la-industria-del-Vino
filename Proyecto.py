# -*- coding: utf-8 -*-
"""Caso_Estudio_13_Marzo_2024 (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s0iaGOLxSRt7QDB1Rm_1Nk6w94bUlX4v

#Caso de estudio

**Título del Caso:** Detección de Fraude en la Industria del Vino: Un Enfoque de Aprendizaje Automático

**Resumen Ejecutivo:**
Este caso se centra en una empresa distribuidora de vinos de alta calidad que recientemente ha sido víctima de fraude por parte de un proveedor deshonesto. La empresa se especializa en la exportación de vinos de calidad extrema y alto valor, pero su reputación se vio comprometida cuando descubrieron que habían sido engañados al recibir vinos de baja calidad etiquetados como productos premium. En respuesta a esta situación, la empresa ha decidido emplear tecnología de aprendizaje automático para detectar posibles fraudes en sus muestras de vino. Los estudiantes asumirán el papel de analistas de datos contratados por la empresa para desarrollar un modelo de aprendizaje automático que pueda predecir si un vino es "Legítimo" o "Fraude" basado en características químicas.

**Contexto:**
La industria del vino está plagada de fraudes, desde la adulteración de productos hasta la falsificación de etiquetas. Estos actos ilícitos pueden tener un impacto devastador en la reputación de una empresa y, en última instancia, en sus ingresos. Con la creciente disponibilidad de datos y avances en la tecnología de aprendizaje automático, las empresas están recurriendo a métodos más avanzados para protegerse contra el fraude y preservar la integridad de sus productos.

**Objetivos de Aprendizaje:**
- Comprender los desafíos asociados con la detección de fraudes en la industria del vino.
- Familiarizarse con el proceso de desarrollo de un modelo de aprendizaje automático para clasificar muestras de vino como "Legítimo" o "Fraude".
- Aplicar técnicas de análisis de datos y aprendizaje automático para abordar un problema empresarial específico.

**Desarrollo del Caso:**
1. **Introducción al Problema:**
   - Presentación del caso de fraude experimentado por la empresa distribuidora de vinos.
   - Explicación de la necesidad de desarrollar un modelo de aprendizaje automático para detectar posibles fraudes en las muestras de vino.

2. **Exploración del Conjunto de Datos:**
   - Análisis de las características químicas del conjunto de datos de vino proporcionado.
   - Identificación de posibles relaciones entre las características y la autenticidad del vino.

3. **Desarrollo del Modelo:**
   - Trabajar en la ingeniería de los atributos del dataset para que sean propicios para el entrenamiento del algoritmo seleccionado
   - División del conjunto de datos en conjuntos de entrenamiento y prueba.
   - Selección de algoritmos de aprendizaje automático adecuados para la clasificación de vinos.
   - Explorar el uso de varios algoritmos tales como LogReg, KNN, SVM o algún otro que se identifique propicio para resolver el problema.
   - Entrenamiento del modelo utilizando características químicas como variables predictoras y la autenticidad del vino como variable objetivo.

4. **Evaluación del Modelo:**
   - Evaluación del rendimiento del modelo utilizando métricas de evaluación apropiadas (precisión, recall, F1-score, etc.).
   - Análisis de la capacidad del modelo para detectar fraudes en las muestras de vino.

5. **Implementación y Recomendaciones:**
   - Desarollar una interfaz de usuario usando Streamlit y permita explicar el modelo.
   - Recomendaciones para la integración del modelo en los procesos de control de calidad de la empresa.

**Preguntas para Discusión en equipo:**

Para esta parte del ejercicio, cada integrante del equipo explica su notebook con el que soluciono. Los demás dan retroalimentación o consideraciones.

Es importante que todos los integrantes contribuyan con sus hallazgos y usen el enfoque de aprendizaje estadístico que han aprendido en clase
1. ¿Qué algoritmo de aprendizaje supervisado hace sentido utilizar?
2. ¿Cuáles son las ventajas y limitaciones de utilizar un enfoque de aprendizaje automático para abordar este problema?
3. ¿Este problema se puede resolver con aprendizaje estadístico? ¿Qué retos afronto cada equipo?
4. ¿Cómo deben estructurar el notebook de Jupyter para que sea entendible y utilizado para explicar a la empresa distribuidora las conclusiones?
5. ¿Cuál es la arquitectura de cómputo que se debe implementar para almacenar el dataset, entrenar al algoritmo y desplegarlo para que infiera? Consideren que este va a ser un proceso que va a utilizarse para soportar los procesos de aseguramiento de calidad de la empresa distribuidora

#Ingestion del dato
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder

df=pd.read_csv('wine_fraud.csv')

df.head()

"""Antes de explorar los datos, la columna type se codifica a dos categorias binarias"""

df=pd.get_dummies(df,columns=['type'])

"""y se codifica label como categorías numéricas"""

labelencoder = LabelEncoder()

df['label']=labelencoder.fit_transform(df['quality'])

"""el DataFrame con el que se va a trabajar, aun se deja la columna quality"""

df.head()

df['label'].unique()

df.info()

df.columns

df

"""#Análisis exploratorio de datos EDA

obtener estadísticas de las columnas numéricas
"""

statistics=df.describe()

statistics

numeric_columns=df.describe().columns

numeric_columns

"""Probando que se pueda obtener percentil 25% y percentil 75%"""

print(statistics['free sulfur dioxide']['25%'])
print(statistics['free sulfur dioxide']['75%'])

"""Buscar anomalías"""

outliers = {}
for col in numeric_columns:
   q1=statistics[col]['25%']
   q3=statistics[col]['75%']
   min_col=statistics[col]['min']
   max_col=statistics[col]['max']
   iqr = q3 - q1
   lower_bound = q1 - 1.5 * iqr
   upper_bound = q3 + 1.5 * iqr
   print(col,lower_bound,(df[df[col] < lower_bound][col]).count(),upper_bound,(df[df[col] > upper_bound][col]).count())

# Set the layout for the plots
plt.figure(figsize=(18, 25))

# Iterate through the numeric columns and create a histplot for each
for i, col in enumerate(numeric_columns):
    plt.subplot(8, 4, i + 1)
    sns.histplot(df[col], bins=50)
    plt.title(col)
    plt.tight_layout(h_pad=5, w_pad=5)

# Display the plot
plt.show()

fig, axes = plt.subplots(nrows=5, ncols=3, figsize=(15, 10))
axes = axes.ravel()

for idx, col in enumerate(numeric_columns):
    ax = axes[idx]
    df.boxplot(column=col, ax=ax)
    ax.set_title(col)

plt.tight_layout()
plt.show()

"""Correlación de los atributos"""

df.corr()

# Calculate the correlation matrix
correlation_matrix = df.corr()

# Set the layout for the heatmap
plt.figure(figsize=(18, 15))

# Create the heatmap
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f")

# Display the heatmap
plt.show()

sns.pairplot(df.dropna(), hue='label',height=4,vars=["fixed acidity","pH","alcohol"],kind='scatter')
plt.show()

"""Contar el numero de datos clasificado como legitimo"""

count_legit = df[df['label'] == 0].shape[0]
print(f"Number of legitimate wines: {count_legit}")

"""Contar el numero de datos clasificado como fraudulentos"""

count_fraud = df[df['label'] == 1].shape[0]
print(f"Number of fraudulent wines: {count_fraud}")

labels = ['Legitimate', 'Fraudulent']
counts = [count_legit, count_fraud]
colors = ['green', 'red']

plt.bar(labels, counts, color=colors)
plt.title('Legitimate vs. Fraudulent Wines')
plt.xlabel('Type')
plt.ylabel('Count')
plt.show()

"""el dataset está desequilibrado

Partiendo de que los features no están fuertemente correlacionados y que hay desbalance en las categorías, se va tratar de equilibrar los datos
"""

import pandas as pd
from sklearn.utils import resample

# Separate the legitimate and fraudulent wines
legit_wines = df[df['label'] == 0]
fraud_wines = df[df['label'] == 1]

# Upsample the fraudulent wines to match the number of legitimate wines
fraud_upsampled = resample(fraud_wines, replace=True, n_samples=count_legit, random_state=42)

# Combine the upsampled fraudulent wines with the legitimate wines
df_balanced = pd.concat([legit_wines, fraud_upsampled])

# Shuffle the rows of the balanced dataset
df_balanced = df_balanced.sample(frac=1, random_state=42)

# Print the count of legitimate and fraudulent wines in the balanced dataset
print(f"Number of legitimate wines in balanced dataset: {df_balanced[df_balanced['label'] == 0].shape[0]}")
print(f"Number of fraudulent wines in balanced dataset: {df_balanced[df_balanced['label'] == 1].shape[0]}")

df_balanced.info()

"""Eliminar la columna quality"""

df_balanced.drop('quality',axis=1,inplace=True)

"""#Entrenamiento y pruebas"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,f1_score, recall_score, precision_score
from sklearn.metrics import confusion_matrix

# Separate features and target
X = df_balanced.drop('label', axis=1)
y = df_balanced['label']

"""Escalar los datos antes de entrenar a KNN"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled= scaler.fit_transform(X)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.1, random_state=42)

# Create a KNN classifier with k=5
knn = KNeighborsClassifier(n_neighbors=9)

# Train the KNN classifier
knn.fit(X_train, y_train)
y_pred = knn.predict(X_train)
cm=confusion_matrix(y_train,y_pred)
print(cm)
# Evaluate the accuracy of the KNN classifier
accuracy = accuracy_score(y_train, y_pred)
print(f"Accuracy: {accuracy:.2f}")
precision = precision_score(y_train, y_pred)
print(f"Precision: {precision:.2f}")
recall = recall_score(y_train, y_pred)
print(f"Recall: {recall:.2f}")
f1 = f1_score(y_train, y_pred)
print(f"F1: {f1:.2f}")

"""el modelo con datos de entreanmiento presenta un 81% de exactitud y F1 al 81%"""

y_pred = knn.predict(X_test)
cm=confusion_matrix(y_test,y_pred)
print(cm)
# Evaluate the accuracy of the KNN classifier
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")
precision = precision_score(y_test, y_pred)
print(f"Precision: {precision:.2f}")
recall = recall_score(y_test, y_pred)
print(f"Recall: {recall:.2f}")
f1 = f1_score(y_test, y_pred)
print(f"F1: {f1:.2f}")

"""el modelo con datos de entreanmiento presenta un 68% de exactitud y F1 al 72%

Esto implica que el modelo está presentando una situación de overfitting

Realizar busqueda de parametros de KNN
"""

from sklearn.model_selection import GridSearchCV

# Define the grid of hyperparameters to search
param_grid = {
    'n_neighbors': [3, 5, 7, 9, 11, 13, 15]
}

# Create a KNN classifier
knn = KNeighborsClassifier()

# Create a GridSearchCV object
grid_search = GridSearchCV(knn, param_grid, cv=5)

# Fit the GridSearchCV object to the training data
grid_search.fit(X_train, y_train)

# Print the best parameters
print(grid_search.best_params_)

# Print the best score
print(grid_search.best_score_)

# Predict the labels of the test data using the best KNN classifier
y_pred = grid_search.best_estimator_.predict(X_train)

# Evaluate the accuracy of the best KNN classifier
cm=confusion_matrix(y_train,y_pred)
print(cm)
accuracy = accuracy_score(y_train, y_pred)
print(f"Accuracy: {accuracy:.2f}")
f1 = f1_score(y_train, y_pred)
print(f"F1: {f1:.2f}")

# Predict the labels of the test data using the best KNN classifier
y_pred = grid_search.best_estimator_.predict(X_test)

# Evaluate the accuracy of the best KNN classifier
cm=confusion_matrix(y_test,y_pred)
print(cm)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")
f1 = f1_score(y_test, y_pred)
print(f"F1: {f1:.2f}")

"""Con el mejor parámetro, sigue presentandose la situación de que el modelo está en situación de underfitting

Se va a probar como el modelo se comporta con el datasxet original

Quitar quality del dataset original
"""

df_original=df.drop('quality',axis=1)
df_original
X1=df_original.drop('label',axis=1)
y1=df['label']

"""Escalar"""

sc=StandardScaler()
X1_scaled=sc.fit_transform(X1)

model=grid_search.best_estimator_

"""Predecir con la totalidad del dataset original"""

y_pred_1=model.predict(X1_scaled)

"""El modelo clasifica como fraudulento a muchos datos de la muestra"""

confusion_matrix(y1,y_pred_1)

accuracy_score(y1,y_pred_1)

precision_score(y1,y_pred_1)

recall_score(y1,y_pred_1)

f1_score(y1,y_pred_1)

"""Revisar si otro modelo puede clasificar mejor, por ejemplo, Support Vector Machine"""

# Support vector machine

from sklearn.svm import SVC

# Create a support vector classifier
svc = SVC()

# Train the support vector classifier
svc.fit(X_train, y_train)

# Predict the labels of the test data using the support vector classifier
y_pred = svc.predict(X_test)

# Evaluate the accuracy of the support vector classifier
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")
f1 = f1_score(y_test, y_pred)
print(f"F1: {f1:.2f}")

# Define the grid of hyperparameters to search
param_grid = {
    'C': [0.1, 1, 10],
    'kernel': ['linear'],
}

# Create a GridSearchCV object
grid_search = GridSearchCV(svc, param_grid, cv=5)

# Fit the GridSearchCV object to the training data
grid_search.fit(X_train, y_train)

# Print the best parameters
print(grid_search.best_params_)

# Print the best score
print(grid_search.best_score_)

# Predict the labels of the test data using the best support vector classifier
y_pred = grid_search.best_estimator_.predict(X_train)

# Evaluate the accuracy of the best support vector classifier
accuracy = accuracy_score(y_train, y_pred)
print(f"Accuracy: {accuracy:.2f}")
f1 = f1_score(y_train, y_pred)
print(f"F1: {f1:.2f}")

# Predict the labels of the test data using the best support vector classifier
y_pred = grid_search.best_estimator_.predict(X_test)

# Evaluate the accuracy of the best support vector classifier
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")
f1 = f1_score(y_test, y_pred)
print(f"F1: {f1:.2f}")

"""Los resultados son similares con SVM como clasificador.

Esto implica que el error no es por modelar sino por el dataset de origen

#Aprendizaje no supervisado

Utilizar K Means para encontrar patrones
"""

# prompt: usando df, y excluyendo quality y label, realizar un análsis de conglomerado usando K-Means

from sklearn.cluster import KMeans

# Separate features and target
X = df.drop(['quality', 'label'], axis=1)

# Scale the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Perform K-means clustering with 3 clusters
kmeans = KMeans(n_clusters=2)
kmeans.fit(X_scaled)

# Get cluster labels for each data point
cluster_labels = kmeans.labels_

# Add cluster labels to the DataFrame
df['Cluster'] = cluster_labels

# Analyze the clusters
df.groupby('Cluster').describe()

df_nuevo = df
df_nuevo.drop('quality',axis=1,inplace=True)
df_nuevo.drop('label',axis=1,inplace=True)

# Calculate the correlation matrix
correlation_matrix = df_nuevo.corr()

# Set the layout for the heatmap
plt.figure(figsize=(18, 15))

# Create the heatmap
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f")

# Display the heatmap
plt.show()

sns.pairplot(df_nuevo.dropna(), hue='Cluster',height=4,vars=["fixed acidity","pH","alcohol"],kind='scatter')
plt.show()

"""El retiquetar se mejoro la correlación!

Entrenar con SVM con este enfoque
"""

X= df_nuevo.drop('Cluster',axis=1)
y= df_nuevo['Cluster']

count_legit = df[df['Cluster'] == 0].shape[0]
print(f"Number of legitimate wines: {count_legit}")

count_fraudulent = df[df['Cluster'] == 1].shape[0]
print(f"Number of fraudulent wines: {count_fraudulent}")

scaler=StandardScaler()
X_scaled=scaler.fit_transform(X)

#  entrenar con SVM usando X_scaled e y con 20% de datos de prueba

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.1, random_state=42)

# Create a support vector classifier
svc = SVC()

# Train the support vector classifier
svc.fit(X_train, y_train)
print(svc.C)

# Predict the labels of the test data using the support vector classifier
y_pred = svc.predict(X_train)

# Evaluate the accuracy of the support vector classifier
cm = confusion_matrix(y_train, y_pred)
print(cm)
accuracy = accuracy_score(y_train, y_pred)
print(f"Accuracy: {accuracy:.6f}")
f1 = f1_score(y_train, y_pred)
print(f"F1: {f1:.6f}")



# Predict the labels of the test data using the support vector classifier
y_pred = svc.predict(X_test)

# Evaluate the accuracy of the support vector classifier
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.6f}")
f1 = f1_score(y_test, y_pred)
print(f"F1: {f1:.6f}")

#  KNNClassifer


# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.1, random_state=42)


# Define the grid of hyperparameters to search
param_grid = {
    'n_neighbors': [3, 5, 7, 9, 11, 13, 15]
}

# Create a GridSearchCV object
grid_search = GridSearchCV(knn, param_grid, cv=5)

# Fit the GridSearchCV object to the training data
grid_search.fit(X_train, y_train)

# Print the best parameters
print(grid_search.best_params_)

# Print the best score
print(grid_search.best_score_)

# Predict the labels of the test data using the best KNN classifier
y_pred = grid_search.best_estimator_.predict(X_test)

# Evaluate the accuracy of the best KNN classifier
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy on test set with best KNN classifier: {accuracy:.6f}")

# prompt: aprendizaje usando Logistic Regression, imprimir confusion matrix, accuracy y f1

from sklearn.linear_model import LogisticRegression

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.1, random_state=42)

# Create a LogisticRegression classifier
logistic_regression = LogisticRegression()

# Train the LogisticRegression classifier
logistic_regression.fit(X_train, y_train)

# Predict the labels of the test data using the LogisticRegression classifier
y_pred = logistic_regression.predict(X_test)

# Evaluate the LogisticRegression classifier
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy on test set with LogisticRegression classifier: {accuracy:.6f}")
f1 = f1_score(y_test, y_pred)
print(f"F1 score on test set with LogisticRegression classifier: {f1:.6f}")

"""Al retiquetar con K-Means, se reajusto el dataset y la correlación mejoró!

#Persistir el modelo

En el escenario de que la empresa distribuidora acepte el modelo con SVM, el siguiente paso es preparar la inferencia y hacer una aplicación con Streamlit.

El siguiente codigo muestra como persistir el modelo, el LabelEncoder y el StandardScaler
"""

model =svc
model

# prompt: persistir al modelo

import pickle

# Save the model to a file
with open('model.pkl', 'wb') as file:
  pickle.dump(model, file)

# Load the model from the file
with open('model.pkl', 'rb') as file:
  loaded_model = pickle.load(file)

# Use the loaded model to make predictions
y_pred = loaded_model.predict(X_test)

# prompt: persistir scaler

# Save the scaler to a file
with open('scaler.pkl', 'wb') as file:
  pickle.dump(scaler, file)

# Load the scaler from the file
with open('scaler.pkl', 'rb') as file:
  loaded_scaler = pickle.load(file)

loaded_scaler.mean_

#  persisit LabelEncoder

with open('label_encoder.pkl', 'wb') as file:
  pickle.dump(labelencoder, file)

svc_model = {
    'model': model,
    'labelencoder': labelencoder,
    'scaler': scaler,
}
with open('svc_model.pkl','wb') as file:
   pickle.dump(svc_model, file)

"""#Conclusión

Aplicar Machine Learning para detectar vinos que tiene fraude, no es recomendable.

Aunque se hizo un ajuste para etiquetar los valores observados, se recomienda que se realice un monitoreo de la inferencia y comparar contra lo observado, antes de usar la aplicación de inferencia.

Es posible que se requieran de distintos atributos y que no sea posible infererir a partir de las propiedades químicas.


"""